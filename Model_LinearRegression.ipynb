{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp = pd.read_csv(\"/50_Startups.csv\")\n",
    "Exp.head()\n",
    "Exp.dtypes\n",
    "Exp.corr()\n",
    "sb.scatterplot(Exp.RND,Exp.PROFIT)\n",
    "sb.regplot(Exp.RND,Exp.PROFIT)\n",
    "# Model Training  \n",
    "# X = Predictor\n",
    "# Y = Target / Outcome\n",
    "X = Exp[['RND']] \n",
    "Y = Exp[['PROFIT']]\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(X,Y,test_size = 0.2,random_state = 5)\n",
    "print(xtrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytrain.shape)\n",
    "print(ytest.shape)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "Model = lr.fit(xtrain,ytrain)\n",
    "y_pred = Model.predict(xtest)\n",
    "y_pred\n",
    "b0 = Model.intercept_\n",
    "b0\n",
    "b1 = Model.coef_\n",
    "b1\n",
    "# Dataframe  : Actual value vs Predicted value\n",
    "R = pd.DataFrame(xtest)\n",
    "R['Actual Profit'] = y_pred\n",
    "R['Predicted Profit'] = ytest\n",
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error / accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between Actual & Predicted  - Error value\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = mean_absolute_error(ytest,y_pred)\n",
    "print(\"Overall Error/Difference : %5f\"%(MAE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression with Categorial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Categorical to numeric\n",
    "# One Hot Encoding & Label Encoding\n",
    "\n",
    "import pandas as pd\n",
    "A = pd.read_csv(\"/iris.csv\")\n",
    "H = ['Sno.','Sepal_L','Sepal_W','Petal_L','Petal_W','Species']\n",
    "A = pd.read_csv(\"/iris.csv\", header = None,skiprows=1,names = H)\n",
    "A.head()\n",
    "A.corr()\n",
    "import seaborn as sb\n",
    "# Categorical + Contineous Data plot\n",
    "sb.boxplot(A.Species,A.Petal_L)\n",
    "# Convert Categorical data to numeric \n",
    "pd.get_dummies(A.Species)\n",
    "A.join(pd.get_dummies(A.Species))\n",
    "B = A.join(pd.get_dummies(A.Species))\n",
    "B\n",
    "# Categorical & Contineous\n",
    "X = B[['setosa','versicolor','virginica']]\n",
    "Y = B[[‘Petal_L']]\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(X,Y,test_size = 0.20,random_state = 5 )\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "\n",
    "Model = lr.fit(xtrain,ytrain)\n",
    "y_pred = Model.predict(xtest)\n",
    "y_pred\n",
    "\n",
    "b0 = Model.intercept_\n",
    "b0\n",
    "\n",
    "b1 = Model.coef_\n",
    "b1\n",
    "\n",
    "# Actual vs Predicted Profit\n",
    "R = pd.DataFrame(xtest)\n",
    "R['Actual Petal_L'] = ytest\n",
    "R['Predicted Petal_L'] = y_pred\n",
    "R\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = pd.read_csv(\"/50_Startups.csv\")\n",
    "T.head()\n",
    "T.corr()\n",
    "# Strong Correlation : Target : Profit || Predictor : RND+MKT as per data \n",
    "# Will check for all the combinations as :\n",
    "# 1. RND+ADMIN+MKT >> PROFIT\n",
    "# 2. RND+ADMIN >> PROFIT\n",
    "# 3. RND+MKT >> PROFIT\n",
    "# 4. ADMIN+MKT >> PROFIT\n",
    "# Multi Linear Regression\n",
    "# Combination : 1. RND+ADMIN+MKT >> PROFIT\n",
    "X = T[['RND','ADMIN','MKT']] # Predictor\n",
    "Y = T[['PROFIT']] # Target\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(X,Y,test_size = 0.2,random_state = 5)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "Model = lr.fit(xtrain,ytrain)\n",
    "y_pred = Model.predict(xtest)\n",
    "y_pred\n",
    "b0 = Model.intercept_\n",
    "b0\n",
    "b1 = Model.coef_\n",
    "b1\n",
    "# Actual vs Predicted Profit\n",
    "R = pd.DataFrame(xtest)\n",
    "R['Actual Profit'] = ytest\n",
    "R['Predicted Profit'] = y_pred\n",
    "R\n",
    "\n",
    "#### Try Random State with For loop :: Range\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between Actual & Predicted Profit\n",
    "# Error - MAE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = mean_absolute_error(ytest,y_pred)\n",
    "print(\"Overall Error %.3f”%(MAE))\n",
    "#*******************************\n",
    "# Error - OLS >> Adjusted R2\n",
    "from statsmodels.api import OLS,add_constant\n",
    "xconstant = add_constant(xtrain)\n",
    "ols = OLS(ytrain,xconstant)\n",
    "Error = ols.fit()\n",
    "Error.summary()\n",
    "# Adj. R-Squared\n",
    "# *******************************\n",
    "\"\"\"# Error Comparision\n",
    "# 1. RND+ADMIN+MKT >> PROFIT\n",
    "MAE = 5680.177\n",
    "OLS = 0.939\n",
    "# 2. RND+ADMIN >> PROFIT\n",
    "MAE = 4873.134\n",
    "OLS = 0.935\n",
    "# 3. RND+MKT >> PROFIT\n",
    "MAE = 5679.963\n",
    "OLS = 0.941\n",
    "# 4. ADMIN+MKT >> PROFIT \n",
    "MAE = 26020.728\n",
    "OLS = 0.647\n",
    "# Result : Best >> 3.RND+MKT >> PROFIT\n",
    "MAE = 5679.963\n",
    "OLS = 0.941  < Preference given to Adj. R-Squared>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between Actual & Predicted Profit\n",
    "# Error - MAE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = mean_absolute_error(ytest,y_pred)\n",
    "print(\"Overall Error %.3f\"%(MAE))\n",
    "\n",
    "# Error - OLS >> Adjusted R2\n",
    "from statsmodels.api import OLS,add_constant\n",
    "xconstant = add_constant(xtrain)\n",
    "ols = OLS(ytrain,xconstant)\n",
    "Error = ols.fit()\n",
    "Error.summary()\n",
    "\n",
    "# Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit_transform(A.Species)\n",
    "A['NS']= le.fit_transform(A.Species)\n",
    "A[’NS']\n",
    "# Categorical & Contineous\n",
    "X = A[['NS']]\n",
    "Y = A[[‘Petal_L']]\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(X,Y,test_size = 0.20,random_state = 5 )\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "\n",
    "Model = lr.fit(xtrain,ytrain)\n",
    "y_pred = Model.predict(xtest)\n",
    "y_pred\n",
    "\n",
    "b0 = Model.intercept_\n",
    "b0\n",
    "\n",
    "b1 = Model.coef_\n",
    "b1\n",
    "\n",
    "# Actual vs Predicted Profit\n",
    "R = pd.DataFrame(xtest)\n",
    "R['Actual Petal_L'] = ytest\n",
    "R['Predicted Petal_L'] = y_pred\n",
    "R\n",
    "\n",
    "# Difference between Actual & Predicted Profit\n",
    "# Error - MAE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = mean_absolute_error(ytest,y_pred)\n",
    "print(\"Overall Error %.3f”%(MAE))\n",
    "\n",
    "# Error - OLS >> Adjusted R2\n",
    "from statsmodels.api import OLS,add_constant\n",
    "xconstant = add_constant(xtrain)\n",
    "ols = OLS(ytrain,xconstant)\n",
    "Error = ols.fit()\n",
    "Error.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation >> Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.read_csv(\"/iris.csv\")\n",
    "H = ['Sno','Sepal_L','Sepal_W','Petal_L','Petal_W','Species']\n",
    "A = pd.read_csv(\"/iris.csv\",header = None,skiprows=1,names = H)\n",
    "A.head()\n",
    "A.corr()\n",
    "\"\"\"\n",
    "#*************************************************************\n",
    "# Analysis\n",
    "# Colinearity 1. Sepal_L vs Petal_L* & Petal_W\n",
    "#             2. Petal_L vs Sepal_L & Petal_W*\n",
    "#             3. Petal_W vs Sepal_L & Petal_L*\n",
    "# '*' Strong colinearity\n",
    "\n",
    "A. Sepal_L vs Petal_L*    --- > Petal_L* vs Sepal_L\n",
    "                                            ---->>> [ Petal_L* vs Petal_W* & Sepal_L ]\n",
    "B. Petal_L vs Petal_W*    --- > Petal_L* vs Petal_W*\n",
    "   Petal_W vs Petal_L*\n",
    " \n",
    " [ Petal_L - Target ]\n",
    " > Petal_W - Predictor 0.962865\n",
    " > Sepal_L - Predictor 0.871754 \n",
    " \"\"\"\n",
    "#*************************************************************\n",
    "# Feature selection : Target & Predictor\n",
    "X = A[[\"Petal_W\",\"Sepal_L\"]]\n",
    "Y = A[[\"Petal_L\"]]\n",
    "\n",
    "# Model Training\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(X,Y,test_size = 0.2, random_state = 5)\n",
    "# Ridge Regression Model\n",
    "from sklearn.linear_model import Ridge\n",
    "rd = Ridge()\n",
    "q = []\n",
    "m = 0.000001\n",
    "for i in range(1,100,1):\n",
    "    m = m+0.000005 # Increment\n",
    "    q.append(m)\n",
    "q   \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# tp - tuning parameter\n",
    "tp = {'alpha':q}\n",
    "cv = GridSearchCV(rd,tp,scoring='neg_mean_absolute_error',cv=4)\n",
    "cvModel = cv.fit(xtrain,ytrain)\n",
    "cvModel.best_params_['alpha']\n",
    "x = cvModel.best_params_['alpha']\n",
    "\n",
    "# Ridge Training\n",
    "rd = Ridge(alpha = x)\n",
    "Model = rd.fit(xtrain,ytrain)\n",
    "y_pred = Model.predict(xtest)\n",
    "y_pred\n",
    "b0 = Model.intercept_\n",
    "b0\n",
    "b1 = Model.coef_\n",
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = mean_absolute_error(ytest,y_pred)\n",
    "print(\"Overall Error : %.7f\"%(MAE))\n",
    "\n",
    "# Error - OLS >> Adjusted R2\n",
    "from statsmodels.api import OLS,add_constant\n",
    "xconstant = add_constant(xtrain)\n",
    "ols = OLS(ytrain,xconstant)\n",
    "Error = ols.fit()\n",
    "Error.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression Model\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "la = Lasso()\n",
    "\n",
    "q = []\n",
    "m = 0.000001\n",
    "for i in range(1,100,1):\n",
    "    m = m+0.000005 # Increment\n",
    "    q.append(m)\n",
    "q    \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# tp - tuning parameter\n",
    "tp = {'alpha':q}\n",
    "cv = GridSearchCV(rd,tp,scoring='neg_mean_absolute_error',cv=4)\n",
    "cvModel = cv.fit(xtrain,ytrain)\n",
    "cvModel.best_params_['alpha']\n",
    "x = cvModel.best_params_['alpha']\n",
    "\n",
    "# Lasso Training\n",
    "la = Lasso(alpha = x)\n",
    "Model = la.fit(xtrain,ytrain)\n",
    "y_pred = Model.predict(xtest)\n",
    "y_pred\n",
    "\n",
    "b0 = Model.intercept_\n",
    "b0\n",
    "\n",
    "b1 = Model.coef_\n",
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = mean_absolute_error(ytest,y_pred)\n",
    "print(\"Overall Error : %.7f\"%(MAE))\n",
    "\n",
    "# Error - OLS >> Adjusted R2\n",
    "from statsmodels.api import OLS,add_constant\n",
    "xconstant = add_constant(xtrain)\n",
    "ols = OLS(ytrain,xconstant)\n",
    "Error = ols.fit()\n",
    "Error.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
